{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import datetime\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Stereo to Mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_to_mono(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            sound = AudioSegment.from_wav(os.path.join(input_dir, filename))\n",
    "            sound = sound.set_channels(1)\n",
    "            name = filename.split(\".\")[0]\n",
    "            sound.export(output_dir + name + \".wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_to_mono('data/', 'data_monowavs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress the wav into smaller format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the 'dataProcessing.py' file into the monowavs folder, then run it to compress the wavs files.  \n",
    "(bitrate = sample rate × number of channels × bits per sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "def feature_extraction(x,fs):\n",
    "    frame_length_s = 0.04 # window length in seconds\n",
    "    frame_length = int(2**np.ceil(np.log2(fs*frame_length_s))) # 40ms window length in samples\n",
    "    # set an overlap ratio of 50 %\n",
    "    hop_length = frame_length//2\n",
    "\n",
    "    # Compute STFT\n",
    "    _,_,X = signal.stft(x, nfft=frame_length,noverlap=hop_length, fs=fs,nperseg=frame_length)\n",
    "    number_frequencies, number_time_frames = X.shape[0]//2 -1, X.shape[1]\n",
    "    X = np.abs(X[0:number_frequencies, :])\n",
    "\n",
    "    # Segmentation\n",
    "    segment_length_s = 0.5 # segment length in seconds\n",
    "    segment_length = int(2**np.ceil(np.log2(segment_length_s/frame_length_s))) # ~0.5s in samples\n",
    "\n",
    "    # Trim the frames that can't be fitted into the segment size\n",
    "    trimmed_X = X[:, :-(number_time_frames%segment_length)]\n",
    "\n",
    "    # Segmentation (number of freqs x number of frames x number of segment x 1). The last dimension is 'channel'.\n",
    "    features = trimmed_X.reshape((number_frequencies,segment_length,-1,1), order='F')\n",
    "    # Transpose the feature to be in form (number of segment x number of freqs x number of frames x 1)\n",
    "    return features.transpose((2,0,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all files and extract training and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data_monowavs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = []\n",
    "groundtruth_features = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        x,fs = sf.read(data_folder + filename)\n",
    "        features = feature_extraction(x, fs)\n",
    "        if \"down\" in filename:\n",
    "            input_features.append(features)\n",
    "        else:   \n",
    "            groundtruth_features.append(features)\n",
    "input_features = np.vstack(input_features)\n",
    "groundtruth_features = np.vstack(groundtruth_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 511, 16, 1)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 511, 16, 1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split \\\n",
    "(input_features,groundtruth_features,test_size=0.4,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save features into .h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(X_train,X_test,y_train,y_test):\n",
    "    with h5py.File('data.hdf5', 'w') as f:\n",
    "        f.create_dataset('X_train', data=X_train)\n",
    "        f.create_dataset('X_test', data=X_test)\n",
    "        f.create_dataset('y_train', data=y_train)\n",
    "        f.create_dataset('y_test', data=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_features(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(features_shape):\n",
    "    input_shape = (features_shape[1],features_shape[2], 1)# (number of freqs x number of frames in a segment x number of channels)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5),\n",
    "            input_shape=input_shape,\n",
    "            activation = \"relu\",\n",
    "            padding = \"same\"))\n",
    "    # model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Conv2D(64, (5, 5),\n",
    "            activation = \"relu\",\n",
    "            padding = \"same\"))\n",
    "\n",
    "    model.add(Conv2D(1, (10, 10),\n",
    "            activation = \"relu\",\n",
    "            padding = \"same\"))\n",
    "\n",
    "    adam = Adam(lr=0.0003)\n",
    "    model.compile(optimizer=adam, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 511, 16, 32)       832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 511, 16, 64)       51264     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 511, 16, 1)        6401      \n",
      "=================================================================\n",
      "Total params: 58,497\n",
      "Trainable params: 58,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), shuffle=True, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test-{date:%Y-%m-%d %H:%M:%S}.txt'.format( date=datetime.datetime.now() ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
